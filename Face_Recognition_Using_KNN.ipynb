{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognise faces using KNN classifiers\n",
    "  \n",
    "  1. Load the training data (numpy arrays of all the persons)\n",
    "         x-values are stored in numpy arrays\n",
    "         y-values we will assign for each person.\n",
    "  2. Read a video stream using OpenCV\n",
    "  3. Extract faces out of it. (Create a test dataset)\n",
    "  4. Use KNN algorithm to predict name of the person.\n",
    "  5. Map the predicted id to name of the user\n",
    "  6. Display the predictions on the screen - using a enclosing box and name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1,x2):\n",
    "    # if the points are as (1,2,3) and (4,5,6), then there dist will be given as: sqrt((1-4)**2 + (2-5)**2 + (3-6)**2 )\n",
    "    # = sqrt(9+9+9) = sqrt(27)\n",
    "    return np.sqrt(sum((x1-x2)**2))\n",
    "\n",
    "def knn(X,Y,query_point,k=5):\n",
    "    dist=[]\n",
    "    m=X.shape[0]\n",
    "    \n",
    "    for i in range(m):\n",
    "        d = distance(query_point,X[i])\n",
    "        dist.append((d,Y[i])) # Storing the distance along with the label as a tuple\n",
    "        \n",
    "    #Now sorting the dist list based on the nearest d values\n",
    "    dist = sorted(dist)\n",
    "    \n",
    "    #for K nearest distance values\n",
    "    dist = dist[:k]\n",
    "    \n",
    "    dist = np.array(dist)\n",
    "    \n",
    "    #To count the no. of unique labels in in the list\n",
    "    new_vals = np.unique(dist[:,1],return_counts=True)\n",
    "    #print(new_vals)\n",
    "    index = new_vals[1].argmax() #it gives the index of label having maximum count\n",
    "    pred = new_vals[0][index]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HBDJivu.npy\n",
      "Loaded Jivu.npy\n",
      "Loaded Rajni.npy\n",
      "Loaded Sanju.npy\n",
      "Loaded Saurabh.npy\n",
      "(45, 30000)\n",
      "(45, 1)\n"
     ]
    }
   ],
   "source": [
    "#Initialising camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#FaceDetection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "skip = 0\n",
    "#file_name = input(\"Enter the name of the person : \")\n",
    "dataset_path = './Face_Data/'   # It acts as the trained data\n",
    "face_data = []\n",
    "labels=[]  # Labels for given file\n",
    "\n",
    "class_id = 0\n",
    "names = {} #Mapping between id and name\n",
    "\n",
    "# Data Preparation\n",
    "for files in os.listdir(dataset_path):\n",
    "    if files.endswith('.npy'):\n",
    "        # Creating a label between class_id and its name\n",
    "        names[class_id]=files[:-4]\n",
    "        print(\"Loaded \"+files)\n",
    "        data_item = np.load(dataset_path+files)\n",
    "        face_data.append(data_item)\n",
    "        \n",
    "        # Creating labels for the classes\n",
    "        target = class_id*np.ones((data_item.shape[0],))\n",
    "        class_id += 1\n",
    "        labels.append(target)\n",
    "trained_face_dataset = np.concatenate(face_data,axis=0)\n",
    "trained_face_labels = np.concatenate(labels,axis=0).reshape((-1,1))\n",
    "\n",
    "print(trained_face_dataset.shape)\n",
    "print(trained_face_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        continue\n",
    "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    \n",
    "    for face in faces[-1:]:\n",
    "        x,y,w,h = face\n",
    "        \n",
    "        offset  = 10 # A value taken for padding around the face\n",
    "        face_sec = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_sec = cv2.resize(face_sec,(100,100))\n",
    "        \n",
    "        # Predicted output label\n",
    "        out = knn(trained_face_dataset,trained_face_labels,face_sec.flatten())\n",
    "        \n",
    "        # Display name and the enclosing box around face\n",
    "        predicted_name = names[int(out)]\n",
    "        cv2.putText(frame,predicted_name,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    \n",
    "    cv2.imshow(\"Faces\",frame)\n",
    "    \n",
    "    KeyPressed = cv2.waitKey(1) & 0xFF\n",
    "    if KeyPressed == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
